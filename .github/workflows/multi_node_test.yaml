name: 'e2e nightly test multi_node'

on:
  workflow_call:
    inputs:
      vllm:
        required: true
        type: string
        description: vllm version to pin
      soc_version:
        required: true
        type: string
        description: use a2 or a3
      image:
        required: false
        type: string
        description: base image for pods
        default: "swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/cann:8.2.rc1-910b-ubuntu22.04-py3.11"
      config_file_path:
        required: true
        type: string
        description: the model config for multi_node test
      replicas:
        required: false
        default: "1"
        type: string
        description: replicas of the k8s cluster
      size:
        required: false
        default: "2"
        type: string
        description: how many pods will be pulled up via lws.yaml, indicates number of nodes we need


# Bash shells do not use ~/.profile or ~/.bashrc so these shells need to be explicitly
# declared as "shell: bash -el {0}" on steps that need to be properly activated.
# It's used to activate ascend-toolkit environment variables.
defaults:
  run:
    shell: bash -el {0}

# only cancel in-progress runs of the same workflow
# and ignore the lint / 8 cards test type
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  e2e:
    # This is a runner with no NPU for k8s controller
    runs-on: linux-aarch64-a3-0
    container:
      image: m.daocloud.io/quay.io/ascend/cann:8.2.rc1-a3-ubuntu22.04-py3.11
      env:
        KUBECONFIG: /tmp/kubeconfig
        KUBECTL: /root/.cache/.kube/kubectl
        NAMESPACE: vllm-project
        LEADER_POD: vllm-0
    steps:
        - name: Install system denpendencies
          run: |
           # configure apt and pip source
           sed -i 's|ports.ubuntu.com|mirrors.tuna.tsinghua.edu.cn|g' /etc/apt/sources.list
           pip config set global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
           pip install jinja2-cli -y

           apt-get update -y && apt-get install -y git curl

           TOKEN=`echo -n "x-access-token:${{ secrets.ADMIN_PTA }}" | base64`
           git config --global http.https://gh-proxy.test.osinfra.cn/.extraheader "AUTHORIZATION: basic $TOKEN"

        - name: Install kubectl
          run: |
            # Install kubectl
            install -o root -g root -m 0755 $KUBECTL /usr/local/bin/kubectl
            
            # Verify kubectl installation
            kubectl version --client=true

        # TODO: Add A2 tests
        - name: Setup kubeconfig for A3
          if: inputs.soc_version == 'a3'
          run: |
            # Decode and save kubeconfig
            echo "${{ secrets.KUBECONFIG_B64 }}" | base64 -d > $KUBECONFIG

        - name: Checkout code
          uses: actions/checkout@v4

        - name: Prepare scripts
          run: |
            # prepare for lws entrypoint scripts
            install -D tests/e2e/multi_node/scripts/run.sh /root/.cache/tests/run.sh

        - name: Launch cluster
          run: |
            set -e

            size="${{ inputs.size }}"
            replicas="${{ inputs.replicas }}"
            image="${{ inputs.image }}"
            config_file_path="${{ inputs.config_file_path }}"

            required_params=("size" "replicas" "image" "config_file_path")
            for param in "${required_params[@]}"; do
              if [ -z "${!param}" ]; then
                echo "Error: Parameter '$param' is required but empty"
                exit 1
              fi
            done

            if ! [[ "$size" =~ ^[0-9]+$ ]] || [ "$size" -lt 1 ]; then
              echo "Error: size must be a positive integer"
              exit 1
            fi
            
            if ! [[ "$replicas" =~ ^[0-9]+$ ]] || [ "$replicas" -lt 1 ]; then
              echo "Error: replicas must be a positive integer"
              exit 1
            fi

            jinja2 tests/e2e/nightly/multi_node/scripts/lws.yaml.jinja2 \
              -D size="$size" \
              -D replicas="$replicas" \
              -D image="$image" \
              -D config_file_path="$config_file_path" \
              --outfile lws.yaml

            kubectl apply -f ./lws.yaml

        - name: Waiting for pod ready
          run: |
            echo "waiting for Pod [$LEADER_POD] in namespace [$NAMESPACE] to Ready..."

            while true; do
              # get pod status
              READY_STATUS=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}')

              if [[ "$READY_STATUS" == "true" ]]; then
                echo "✅ Pod [$LEADER_POD] is Ready!"
                break
              else
                echo "Pod [$LEADER_POD] not ready, waiting..."
                sleep 3
              fi
            done

        - name: Stream logs and monitor pod health
          run: |
            set -euo pipefail

            echo "🚀 Start streaming logs for Pod [$LEADER_POD] ..."
            kubectl logs -f "$LEADER_POD" -n "$NAMESPACE" &
            LOG_PID=$!

            echo "Start monitoring Pod [$LEADER_POD] status ..."
            while true; do
              STATUS=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}')
              if [[ "$STATUS" != "Running" && "$STATUS" != "Succeeded" ]]; then
                echo "❌ Pod [$LEADER_POD] exited abnormally with status: $STATUS"
                kubectl describe pod "$LEADER_POD" -n "$NAMESPACE" || true
                kubectl logs "$LEADER_POD" -n "$NAMESPACE" --previous --all-containers || true
                kill $LOG_PID || true
                exit 1
              fi
              sleep 5
            done &

            MONITOR_PID=$!
            wait $LOG_PID || true
            kill $MONITOR_PID || true

        - name: Generate summary
          if: always()
          run: |
            if [ -f "/root/.cache/test_summary.md" ]; then
              cat /root/.cache/test_summary.md >> "$GITHUB_STEP_SUMMARY"
            else
              echo "No summary file found." >> "$GITHUB_STEP_SUMMARY"
            fi

        - name: Post process
          if: always()
          run: |
            kubectl get pods -n $NAMESPACE
            kubectl delete -f ./lws.yaml
