name: 'e2e test / multi-dp'

on:
  workflow_dispatch:

# Bash shells do not use ~/.profile or ~/.bashrc so these shells need to be explicitly
# declared as "shell: bash -el {0}" on steps that need to be properly activated.
# It's used to activate ascend-toolkit environment variables.
defaults:
  run:
    shell: bash -el {0}

# only cancel in-progress runs of the same workflow
# and ignore the lint / 8 cards test type
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  e2e:
    strategy:
      max-parallel: 2
      matrix:
        vllm_version: [main]
    runs-on: linux-aarch64-a3-0
    container:
      image: m.daocloud.io/quay.io/ascend/cann:8.2.rc1-a3-ubuntu22.04-py3.11
      env:
        KUBECONFIG: /root/.cache/.kube/kubeconfig.yaml
        KUBECTLPATH: /root/.cache/.kube/kubectl
        NAMESPACE: vllm-project
        MODEL_PATH: /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3-W8A8
    steps:
        - name: Install system denpendencies
          run: |
           # configure apt and pip source
           sed -i 's|ports.ubuntu.com|mirrors.tuna.tsinghua.edu.cn|g' /etc/apt/sources.list
           pip config set global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple

           apt-get update -y && apt-get install -y git curl
           TOKEN=`echo -n "x-access-token:${{ secrets.ADMIN_PTA }}" | base64`
           git config --global http.https://gh-proxy.test.osinfra.cn/.extraheader "AUTHORIZATION: basic $TOKEN"

        - name: Install kubectl
          run: |
            install -o root -g root -m 0755 $KUBECTLPATH /usr/local/bin/kubectl
            kubectl version

        - name: Checkout code
          uses: actions/checkout@v4

        - name: Prepare scripts
          run: |
            rm -rf /root/.cache/tests
            mkdir -p /root/.cache/tests
            cp -r tests/e2e/multi_nodes/* /root/.cache/tests/

        - name: Launch cluster
          run: |
            kubectl apply -f tests/e2e/multi_nodes/multi_node_mp/lws.yaml

        - name: Checkout vllm-project/vllm
          uses: actions/checkout@v4
          with:
            repository: vllm-project/vllm
            path: ./vllm-empty
            ref: ${{ matrix.vllm_version }}

        - name: Install vllm
          working-directory: vllm-empty
          run: |
              pip install -r requirements/build.txt --extra-index-url https://download.pytorch.org/whl/cpu
              VLLM_TARGET_DEVICE=empty pip install .

        - name: Install benchmark
          run: |
            pip install -r benchmarks/requirements-bench.txt

        - name: Wait for all pods ready
          run: |
            timeout 7200 bash -c '
            while true; do
                # Check if the pod is healthy
                pod=$(kubectl get pod -l role=leader -n vllm-project -o jsonpath="{.items[0].metadata.name}")
                status=$(kubectl get pod "$pod" -n vllm-project -o jsonpath="{.status.phase}")

                # If pod failed, print the error logs and exit
                if [[ "$status" == "Failed" ]] || [[ "$status" == "CrashLoopBackOff" ]]; then
                echo "❌ Pod $pod failed with status=$status"
                echo "---- Pod logs start ----"
                kubectl logs "$pod" -n vllm-project --previous || kubectl logs "$pod" -n vllm-project
                echo "---- Pod logs end ----"
                exit 1
                fi

                # Check if service is ready
                if curl -sf http://vllm-leader:8080/health > /dev/null; then
                echo "✅ vllm cluster is ready (pod=$pod)"
                exit 0
                fi

                echo "⏳ Waiting for vllm server to start... (pod=$pod, status=$status)"
                sleep 5
            done
            '

        - name: Run benchmark
          run: |
            python ./vllm-empty/benchmarks/benchmark_serving.py --model $MODEL_PATH  \
                --dataset-name random --random-input-len 128 --random-output-len 128 \
                --num-prompts 200  --trust-remote-code --base-url "http://vllm-leader:8080" \
                --request-rate 1

        - name: Post process
          if: always()
          run: |
            kubectl get pods -n $NAMESPACE
            kubectl delete -f tests/multi_node_mp/lws.yaml
