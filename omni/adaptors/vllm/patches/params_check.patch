diff --git a/vllm/entrypoints/openai/protocol.py b/vllm/entrypoints/openai/protocol.py
index 7743ae47f..b0e3fac30 100644
--- a/vllm/entrypoints/openai/protocol.py
+++ b/vllm/entrypoints/openai/protocol.py
@@ -612,23 +612,12 @@ class ChatCompletionRequest(OpenAIBaseModel):
     @model_validator(mode="before")
     @classmethod
     def check_logprobs(cls, data):
-        if (prompt_logprobs := data.get("prompt_logprobs")) is not None:
-            if data.get("stream") and prompt_logprobs > 0:
-                raise ValueError(
-                    "`prompt_logprobs` are not available when `stream=True`.")
-
-            if prompt_logprobs < 0:
-                raise ValueError("`prompt_logprobs` must be a positive value.")
-
-        if (top_logprobs := data.get("top_logprobs")) is not None:
-            if top_logprobs < 0:
-                raise ValueError("`top_logprobs` must be a positive value.")
-
-            if top_logprobs > 0 and not data.get("logprobs"):
-                raise ValueError(
-                    "when using `top_logprobs`, `logprobs` must be set to true."
-                )
-
+        if (_ := data.get("prompt_logprobs")) is not None:
+            raise ValueError("`prompt_logprobs` are not supported")
+        if(_ := data.get("logprobs")) is not None:
+            raise ValueError("`logprobs` are not supported")
+        if(_ := data.get("top_logprobs")) is not None:
+            raise ValueError("`top_logprobs` are not supported")
         return data

     @model_validator(mode="before")
@@ -1004,17 +993,10 @@ class CompletionRequest(OpenAIBaseModel):
     @model_validator(mode="before")
     @classmethod
     def check_logprobs(cls, data):
-        if (prompt_logprobs := data.get("prompt_logprobs")) is not None:
-            if data.get("stream") and prompt_logprobs > 0:
-                raise ValueError(
-                    "`prompt_logprobs` are not available when `stream=True`.")
-
-            if prompt_logprobs < 0:
-                raise ValueError("`prompt_logprobs` must be a positive value.")
-
-        if (logprobs := data.get("logprobs")) is not None and logprobs < 0:
-            raise ValueError("`logprobs` must be a positive value.")
-
+        if (_ := data.get("prompt_logprobs")) is not None:
+            raise ValueError("`prompt_logprobs` is not supported")
+        if (_ := data.get("logprobs")) is not None:
+            raise ValueError("`logprobs` is not supported")
         return data

     @model_validator(mode="before")
diff --git a/vllm/sampling_params.py b/vllm/sampling_params.py
index dc38daa38..63079541f 100644
--- a/vllm/sampling_params.py
+++ b/vllm/sampling_params.py
@@ -424,16 +424,12 @@ class SamplingParams(
             raise ValueError(
                 f"min_tokens must be less than or equal to "
                 f"max_tokens={self.max_tokens}, got {self.min_tokens}.")
-        if self.logprobs is not None and self.logprobs < 0:
-            raise ValueError(
-                f"logprobs must be non-negative, got {self.logprobs}.")
-        if self.prompt_logprobs is not None and self.prompt_logprobs < 0:
-            raise ValueError(f"prompt_logprobs must be non-negative, got "
-                             f"{self.prompt_logprobs}.")
-        if (self.truncate_prompt_tokens is not None
-                and self.truncate_prompt_tokens < 1):
-            raise ValueError(f"truncate_prompt_tokens must be >= 1, "
-                             f"got {self.truncate_prompt_tokens}")
+        if self.logprobs is not None:
+            raise ValueError("logprobs is not supported.")
+        if self.prompt_logprobs is not None:
+            raise ValueError("prompt_logprobs is not supported.")
+        if self.truncate_prompt_tokens is not None:
+            raise ValueError("truncate_prompt_tokens is not supported.")
         assert isinstance(self.stop_token_ids, list)
         if not all(isinstance(st_id, int) for st_id in self.stop_token_ids):
             raise ValueError(f"stop_token_ids must contain only integers, "
@@ -448,6 +444,8 @@ class SamplingParams(
         if self.best_of != self._real_n and self.output_kind == (
                 RequestOutputKind.DELTA):
             raise ValueError("best_of must equal n to use output_kind=DELTA")
+        if self.guided_decoding is not None:
+            raise ValueError("guided decoding is not supported.")

     def _verify_greedy_sampling(self) -> None:
         if self.n > 1:
