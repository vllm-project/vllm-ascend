# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, vllm-ascend team
# This file is distributed under the same license as the vllm-ascend
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
msgid ""
msgstr ""
"Project-Id-Version: vllm-ascend \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-12-17 17:00+0800\n"
"PO-Revision-Date: 2025-12-17 13:05+0800\n"
"Last-Translator: Gemini <support@google.com>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:1
msgid "KV Cache Pool"
msgstr "KV Cache 池 (KV Cache Pool)"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:3
msgid "Why KV Cache Pool?"
msgstr "为什么需要 KV Cache 池？"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:5
msgid ""
"Prefix caching is an important feature in LLM inference that can reduce "
"prefill computation time drastically."
msgstr "前缀缓存 (Prefix Caching) 是 LLM 推理中的一项重要功能，可以大幅减少预填充 (prefill) 计算时间。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:7
msgid ""
"However, the performance gain from prefix caching is highly dependent on "
"cache hit rate, while cache hit rate can be limited if one only uses HBM "
"for kv cache storage."
msgstr "然而，前缀缓存带来的性能收益高度依赖于缓存命中率，而如果仅使用 HBM 存储 KV Cache，缓存命中率会受到很大限制。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:9
msgid ""
"Hence, KV Cache Pool is proposed to utilize various types of storages "
"including HBM,DRAM and SSD, making a pool for KV Cache storage, while "
"making the prefix of requests visible across all nodes, increasing the "
"cache hit rate for all requests."
msgstr ""
"因此，KV Cache 池被提议用于利用包括 HBM、DRAM 和 SSD 在内的各种存储类型来构建 KV Cache "
"存储池，同时使请求的前缀在所有节点间可见，从而提高所有请求的缓存命中率。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:11
msgid ""
"vLLM Ascend currently supports [MooncakeStore](https://github.com"
"/kvcache-ai/Mooncake): one of the most recognized KV Cache storage "
"engine;"
msgstr ""
"vLLM Ascend 目前支持 [MooncakeStore](https://github.com/kvcache-"
"ai/Mooncake)：最受认可的 KV Cache 存储引擎之一。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:13
msgid ""
"While one can utilize mooncake store in vLLM V1 engine by setting it as a"
" remote backend of LMCache with GPU (see "
"[Tutorial](https://github.com/LMCache/LMCache/blob/dev/examples/kv_cache_reuse/remote_backends/mooncakestore/README.md)),"
" we find it would be better to integrate a connector that directly "
"supports mooncake store and can utilize the data transfer strategy to one"
" that is best fit to Huawei NPU hardware."
msgstr ""
"虽然可以通过将 Mooncake Store 设置为 LMCache 的 GPU 远程后端来在 vLLM V1 "
"引擎中使用它（参见教程），但我们发现最好集成一个直接支持 Mooncake Store 的连接器，并采用最适合华为 NPU 硬件的数据传输策略。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:15
msgid ""
"Hence, we propose to integrate Mooncake Store with a brand new "
"**MooncakeStoreConnectorV1**, which is indeed largly inspired by "
"**LMCacheConnectorV1** (see the `How is MooncakestoreConnectorV1 "
"Implemented?` section)."
msgstr ""
"因此，我们建议通过全新的 **MooncakeStoreConnectorV1** 来集成 Mooncake Store，该连接器很大程度上受到了"
" **LMCacheConnectorV1** 的启发（详见 `MooncakestoreConnectorV1 是如何实现的？` 章节）。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:17
msgid "Usage"
msgstr "用法"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:19
msgid ""
"vLLM Ascend Currently supports Mooncake Store for KV Cache Pool. To "
"enable Mooncake Store, one needs to config `kv-transfer-config` and "
"choose `MooncakeStoreConnector` as KV Connector."
msgstr ""
"vLLM Ascend 目前为 KV Cache 池支持 Mooncake Store。要启用 Mooncake Store，需要配置 `kv-"
"transfer-config` 并选择 `MooncakeStoreConnector` 作为 KV 连接器。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:21
msgid ""
"For step-by-step deployment and configuration, please refer to the [KV "
"Pool User "
"Guide](https://docs.vllm.ai/projects/ascend/en/latest/user_guide/feature_guide/kv_pool.html)."
msgstr ""
"有关详细的部署和配置步骤，请参阅 [KV "
"池用户指南](https://docs.vllm.ai/projects/ascend/en/latest/user_guide/feature_guide/kv_pool.html)。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:23
msgid "How it works?"
msgstr "工作原理"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:24
msgid ""
"The KV Cache Pool integrates multiple memory tiers (HBM, DRAM, SSD, etc.)"
" through a connector-based architecture."
msgstr "KV Cache 池通过基于连接器的架构集成了多个内存层（HBM、DRAM、SSD 等）。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:26
msgid ""
"Each connector implements a unified interface for storing, retrieving, "
"and transferring KV blocks between tiers, depending on access frequency "
"and hardware bandwidth."
msgstr "每个连接器都实现了一个统一接口，用于在不同层之间存储、检索和传输 KV 块，具体取决于访问频率和硬件带宽。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:28
msgid ""
"When combined with vLLM’s Prefix Caching mechanism, the pool enables "
"efficient caching both locally (in HBM) and globally (via Mooncake), "
"ensuring that frequently used prefixes remain hot while less frequently "
"accessed KV data can spill over to lower-cost memory."
msgstr ""
"与 vLLM 的前缀缓存机制结合时，该池能够实现在本地（HBM 中）和全局（通过 "
"Mooncake）的高效缓存，确保常用前缀保持热度，而访问频率较低的 KV 数据可以溢出到成本较低的内存中。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:30
msgid "1. Combining KV Cache Pool with HBM Prefix Caching"
msgstr "1. 将 KV Cache 池与 HBM 前缀缓存相结合"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:31
msgid ""
"Prefix Caching with HBM is already supported by the vLLM V1 Engine. By "
"introducing KV Connector V1, users can seamlessly combine HBM-based "
"Prefix Caching with Mooncake-backed KV Pool."
msgstr ""
"vLLM V1 引擎已经支持基于 HBM 的前缀缓存。通过引入 KV Connector V1，用户可以将基于 HBM 的前缀缓存与 "
"Mooncake 支持的 KV 池无缝结合。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:34
msgid ""
"The user can enable both features simply by enabling Prefix Caching, "
"which is enabled by default in vLLM V1 unless the "
"--no_enable_prefix_caching flag is set, and setting up the KV Connector "
"for KV Pool(e.g. the MooncakeStoreConnector)"
msgstr ""
"用户只需启用前缀缓存（vLLM V1 默认启用，除非设置了 `--no_enable_prefix_caching` 标志），并为 KV 池设置 "
"KV 连接器（例如 MooncakeStoreConnector），即可同时启用这两个功能。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:36
msgid "**Workflow**:"
msgstr "**工作流**："

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:38
msgid "The engine first checks for prefix hits in the HBM cache."
msgstr "引擎首先检查 HBM 缓存中的前缀命中情况。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:40
msgid ""
"After getting the number of hit tokens on HBM, it queries the KV Pool via"
" the connector, if there is additional hits in KV Pool, we get the "
"**additional blocks only** from KV Pool, and get the rest of the blocks "
"directly from HBM to minimize the data transfer latency."
msgstr ""
"在获取 HBM 上的命中 token 数量后，它会通过连接器查询 KV 池。如果 KV 池中有额外的命中，我们将**仅从 KV "
"池获取额外的块**，并直接从 HBM 获取其余块，以最大限度地减少数据传输延迟。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:42
msgid ""
"After the KV Caches in KV Pool is load into HBM, the remaining process is"
" the same as Prefix Caching in HBM."
msgstr "在将 KV 池中的 KV Cache 加载到 HBM 后，剩余过程与 HBM 中的前缀缓存一致。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:44
msgid "2. Combining KV Cache Pool with Mooncake PD Disaggregation"
msgstr "2. 将 KV Cache 池与 Mooncake PD 分离 (Disaggregation) 相结合"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:46
msgid ""
"When used together with Mooncake PD (Prefill-Decode) Disaggregation, the "
"KV Cache Pool can further decouple prefill and decode stages across "
"devices or nodes."
msgstr "与 Mooncake PD（预填充-解码）分离技术结合使用时，KV Cache 池可以进一步解耦跨设备或节点的预填充和解码阶段。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:48
msgid ""
"Currently, we only perform put and get operation of KV Pool for **Prefiil"
" Nodes**, and Decode Nodes get their KV Cache from Mooncake P2P KV "
"Connector, i.e. MooncakeConnector."
msgstr ""
"目前，我们仅对**预填充节点 (Prefill Nodes)** 执行 KV 池的 put 和 get 操作，而解码节点通过 Mooncake "
"P2P KV 连接器（即 MooncakeConnector）获取其 KV Cache。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:50
msgid ""
"The key benefit of doing this is that we can keep the gain in performance"
" by computing less with Prefix Caching from HBM and KV Pool for Prefill "
"Nodes while not sacrificing the data transfer efficiency between Prefill "
"and Decode nodes with P2P KV Connector that transfer KV Caches between "
"NPU devices directly."
msgstr ""
"这样做核心优势在于：对于预填充节点，我们可以通过 HBM 和 KV 池的前缀缓存减少计算量来保持性能增益，同时利用 P2P KV 连接器在 NPU"
" 设备间直接传输 KV Cache，不牺牲预填充和解码节点之间的数据传输效率。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:52
msgid ""
"To Enable this feature, we need to setup both Mooncake Connector and "
"Mooncake Store connector with a Multi Connector, which is a KV Connector "
"class provided by vLLM that can call multiple KV Connectors in specific "
"order;"
msgstr ""
"要启用此功能，我们需要使用 Multi Connector 同时设置 Mooncake 连接器和 Mooncake Store 连接器。Multi"
" Connector 是 vLLM 提供的一种 KV 连接器类，可以按特定顺序调用多个 KV 连接器。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:54
msgid ""
"For details, please also refer to the Mooncake Connector Store Deployment"
" Guide."
msgstr "有关详细信息，另请参阅 Mooncake 连接器存储部署指南。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:56
msgid "How is MooncakestoreConnectorV1 Implemented?"
msgstr "MooncakestoreConnectorV1 是如何实现的？"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:57
msgid ""
"**MooncakestoreConnectorV1** inhereits the KV Connector V1 class in vLLM "
"V1: through implementing the required methods defined in the KV connector"
" V1 base class, one can integrate a thrid-party KV cache transfer/storage"
" backend into the vLLM framework."
msgstr ""
"**MooncakestoreConnectorV1** 继承了 vLLM V1 中的 KV Connector V1 "
"类：通过实现基类中定义的必需方法，可以将第三方 KV Cache 传输/存储后端集成到 vLLM 框架中。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:59
msgid ""
"MooncakeStoreConnectorV1 is also largly inspried by LMCacheConnectorV1 in"
" term of the `Lookup Engine`/`Lookup Client` design for looking up KV "
"cache keys, and the `ChunkedTokenDatabase` class for processing tokens "
"into prefix-aware hashes as well as other hashing related designs. On top"
" of this, we have also added our own design including `KVTransferThread` "
"that allows async `get` and `put` of KV caches with multi-threading, and "
"NPU-related data transfer optimization such as removing the `LocalBuffer`"
" in LMCache to remove redundant data transfer."
msgstr ""
"在用于查找 KV Cache 键的 `Lookup Engine`/`Lookup Client` 设计，以及将 token 处理为前缀感知哈希的"
" `ChunkedTokenDatabase` 类及其他哈希相关设计方面，MooncakeStoreConnectorV1 很大程度上受到了 "
"LMCacheConnectorV1 的启发。在此基础上，我们还增加了自有设计，包括支持多线程异步 `get` 和 `put` KV Cache "
"的 `KVTransferThread`，以及针对 NPU 的数据传输优化（如移除 LMCache 中的 `LocalBuffer` "
"以消除冗余数据传输）。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:61
msgid ""
"The KV Connector methods that need to be implemented can be categorized "
"into scheduler-side methods that are called in V1 scheduler and worker-"
"side methods that are called in V1 worker, namely:"
msgstr "需要实现的 KV 连接器方法可以分为在 V1 调度器中调用的调度器端方法和在 V1 工作线程中调用的工作端方法，即："

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:62
msgid "KV Connector Scheduler-Side Methods:"
msgstr "KV 连接器调度器端方法："

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:63
#, fuzzy
msgid ""
"`get_num_new_matched_tokens`: Get prefix cache hit in number of tokens "
"through looking up into the KV pool.   `update_states_after_alloc`:  "
"Update KVConnector state after temporary buffer alloc.   "
"`build_connector_meta`: Attach the connector metadata to the request "
"object.   `request_finished`: Once a request is finished, determine "
"whether request blocks should be freed now or will be sent asynchronously"
" and freed later."
msgstr ""
"`get_num_new_matched_tokens`：通过在 KV 池中查找来获取前缀缓存命中的 token "
"数量。`update_states_after_alloc`：在分配临时缓冲区后更新 KVConnector "
"状态。`build_connector_meta`：将连接器元数据附加到请求对象。`request_finished`：请求完成后，确定是立即释放请求块，还是异步发送后稍后释放。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:67
msgid "Connector Worker-Side Methods:"
msgstr "连接器工作端方法："

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:68
#, fuzzy
msgid ""
"`register_kv_caches`: Register KV cache buffers needed for KV cache "
"transfer.   `start_load_kv`: Perform KV cache load operation that "
"transfers KV cache from storage to device.   `wait_for_layer_load`: "
"Optional; Wait for layer load in layerwise + async KV load scenario.   "
"`save_kv_layer`: Optional Do layerwise KV cache put into KV Pool.   "
"`wait_for_save`: Wait for KV Save to finish if async KV cache save/put."
"   `get_finished` Get request that finished KV transfer, `done_sending` "
"if `put` finished, `done_reciving` if `get` finished."
msgstr ""
"`register_kv_caches`：注册 KV Cache 传输所需的缓冲区。`start_load_kv`：执行从存储到设备的 KV "
"Cache "
"加载操作。`wait_for_layer_load`：（可选）在逐层+异步加载场景下等待层加载。`save_kv_layer`：（可选）将 KV "
"Cache 逐层存入 (put) KV "
"池。`wait_for_save`：如果是异步保存/存入，则等待保存完成。`get_finished`：获取已完成 KV "
"传输的请求，`done_sending` 表示 `put` 完成，`done_reciving` 表示 `get` 完成。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:75
msgid "DFX"
msgstr "DFX (可维护性设计)"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:76
msgid ""
"When looking up a key in KV Pool, if we cannot find the key, there is no "
"Cache Hit for this specific block; we return no hit for this block and do"
" not look up further blocks for current request."
msgstr "在 KV 池中查找键时，如果找不到该键，则该特定块未命中缓存；我们返回该块未命中，并且不再为当前请求查找后续块。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:77
msgid ""
"Similaly, when we are trying to put a block into KV Pool and failed, we "
"do not put further blocks (subject to change)."
msgstr "同样地，当我们尝试将块存入 KV 池失败时，我们不再存入后续块（可能会有变动）。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:79
msgid "Limitation"
msgstr "限制"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:81
msgid ""
"Currently, Mooncake Store for vLLM-Ascend only supports DRAM as the "
"storage for KV Cache pool."
msgstr "目前，用于 vLLM-Ascend 的 Mooncake Store 仅支持 DRAM 作为 KV Cache 池的存储。"

#: ../../source/developer_guide/feature_guide/KV_Cache_Pool_Guide.md:83
msgid ""
"For now, if we successfully looked up a key and found it exists, but "
"failed to get it when calling KV Pool's get function, we just output a "
"log indicating the get operation failed and keep going; hence, the "
"accuracy of that specific request may be affected. We will handle this "
"situation by falling back the request and re-compute everything assuming "
"there's no prefix cache hit (or even better, revert only one block and "
"keep using the Prefix Caches before that)."
msgstr ""
"目前，如果我们成功查找到一个键并发现它存在，但在调用 KV 池的 get "
"函数获取它时失败，我们仅输出一条指示失败的日志并继续运行；因此，该特定请求的准确性可能会受到影响。我们将通过回退请求并假设没有前缀缓存命中的情况下重新计算所有内容来处理此情况（或者更好的方案是：仅回退一个块并继续使用之前的前缀缓存）。"

