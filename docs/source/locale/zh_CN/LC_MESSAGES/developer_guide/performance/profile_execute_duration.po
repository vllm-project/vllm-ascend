# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, vllm-ascend team
# This file is distributed under the same license as the vllm-ascend
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: vllm-ascend\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-07-18 09:01+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.17.0\n"

#: ../../developer_guide/performance/profile_execute_duration.md:1
msgid "Profile Execute Duration"
msgstr "配置执行持续时间"

#: ../../developer_guide/performance/profile_execute_duration.md:3
msgid ""
"The execution duration of each stage (including pre/post-processing, model "
"forward, etc.) usually needs to be captured during a complete inference "
"process. Typically, this is done by using `torch.npu.synchronize()` and "
"obtaining CPU timestamps, which increases the performance overhead of "
"host/device synchronization."
msgstr ""
"在完整的推理过程中，通常需要记录每个阶段（包括前/后处理、模型前向等）的执行时长。一般通过使用 `torch.npu.synchronize()` "
"并获取 CPU 时间戳来实现，这会增加主机/设备同步的性能开销。"

#: ../../developer_guide/performance/profile_execute_duration.md:5
msgid ""
"**To reduce the performance overhead, we add this feature, using the NPU "
"event timestamp mechanism to observe the device execution time "
"asynchronously.**"
msgstr "**为了减少性能开销，我们添加了此功能，使用 NPU 事件时间戳机制异步观测设备的执行时间。**"

#: ../../developer_guide/performance/profile_execute_duration.md:7
msgid "Usage"
msgstr "用法"

#: ../../developer_guide/performance/profile_execute_duration.md:8
msgid ""
"Use the environment variable `VLLM_ASCEND_MODEL_EXECUTE_TIME_OBSERVE` to "
"enable this feature."
msgstr "使用环境变量 `VLLM_ASCEND_MODEL_EXECUTE_TIME_OBSERVE` 来启用此功能。"

#: ../../developer_guide/performance/profile_execute_duration.md:9
msgid ""
"Use the non-blocking API `ProfileExecuteDuration().capture_async` to set "
"observation points asynchronously when you need to observe the execution "
"duration."
msgstr ""
"当你需要观察执行时长时，可以使用非阻塞 API `ProfileExecuteDuration().capture_async` 异步设置观察点。"

#: ../../developer_guide/performance/profile_execute_duration.md:10
msgid ""
"Use the blocking API `ProfileExecuteDuration().pop_captured_sync` at an "
"appropriate time to get and print the execution durations of all observed "
"stages."
msgstr ""
"在适当的时机使用阻塞式 API `ProfileExecuteDuration().pop_captured_sync` "
"获取并打印所有已观察到阶段的执行时长。"

#: ../../developer_guide/performance/profile_execute_duration.md:12
msgid ""
"**We have instrumented the key inference stages (including pre-processing, "
"model forward pass, etc.) for execute duration profiling. Execute the script"
" as follows:**"
msgstr "**我们已经对关键的推理阶段（包括预处理、模型前向传递等）进行了执行时长分析的检测。请按如下方式执行脚本：**"

#: ../../developer_guide/performance/profile_execute_duration.md:17
msgid "Example Output"
msgstr "示例输出"
