# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, vllm-ascend team
# This file is distributed under the same license as the vllm-ascend
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: vllm-ascend\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-07-18 09:01+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.17.0\n"

#: ../../developer_guide/performance/performance_benchmark.md:1
msgid "Performance Benchmark"
msgstr "性能基准"

#: ../../developer_guide/performance/performance_benchmark.md:2
msgid ""
"This document details the benchmark methodology for vllm-ascend, aimed at "
"evaluating the performance under a variety of workloads. To maintain "
"alignment with vLLM, we use the [benchmark](https://github.com/vllm-"
"project/vllm/tree/main/benchmarks) script provided by the vllm project."
msgstr ""
"本文档详细说明了 vllm-ascend 的基准测试方法，旨在评估其在多种工作负载下的性能。为了与 vLLM 保持一致，我们使用 vllm 项目提供的 "
"[benchmark](https://github.com/vllm-project/vllm/tree/main/benchmarks) 脚本。"

#: ../../developer_guide/performance/performance_benchmark.md:4
msgid ""
"**Benchmark Coverage**: We measure offline e2e latency and throughput, and "
"fixed-QPS online serving benchmarks, for more details see [vllm-ascend "
"benchmark scripts](https://github.com/vllm-project/vllm-"
"ascend/tree/main/benchmarks)."
msgstr ""
"**基准测试覆盖范围**：我们测量离线端到端延迟和吞吐量，以及固定 QPS 的在线服务基准测试。更多详情请参见 [vllm-ascend "
"基准测试脚本](https://github.com/vllm-project/vllm-ascend/tree/main/benchmarks)。"

#: ../../developer_guide/performance/performance_benchmark.md:6
msgid "1. Run docker container"
msgstr "1. 运行 docker 容器"

#: ../../developer_guide/performance/performance_benchmark.md:31
msgid "2. Install dependencies"
msgstr "2. 安装依赖项"

#: ../../developer_guide/performance/performance_benchmark.md:38
msgid "3. (Optional)Prepare model weights"
msgstr "3.（可选）准备模型权重"

#: ../../developer_guide/performance/performance_benchmark.md:39
msgid ""
"For faster running speed, we recommend downloading the model in advance："
msgstr "为了更快的运行速度，建议提前下载模型："

#: ../../developer_guide/performance/performance_benchmark.md:44
msgid ""
"You can also replace all model paths in the [json](https://github.com/vllm-"
"project/vllm-ascend/tree/main/benchmarks/tests) files with your local paths:"
msgstr ""
"你也可以将 [json](https://github.com/vllm-project/vllm-"
"ascend/tree/main/benchmarks/tests) 文件中的所有模型路径替换为你的本地路径："

#: ../../developer_guide/performance/performance_benchmark.md:60
msgid "4. Run benchmark script"
msgstr "4. 运行基准测试脚本"

#: ../../developer_guide/performance/performance_benchmark.md:61
msgid "Run benchmark script:"
msgstr "运行基准测试脚本："

#: ../../developer_guide/performance/performance_benchmark.md:66
msgid "After about 10 mins, the output is as shown below:"
msgstr "大约 10 分钟后，输出如下所示："

#: ../../developer_guide/performance/performance_benchmark.md:176
msgid ""
"The result json files are generated into the path `benchmark/results` These "
"files contain detailed benchmarking results for further analysis."
msgstr "结果 json 文件会生成到路径 `benchmark/results`。这些文件包含了用于进一步分析的详细基准测试结果。"
