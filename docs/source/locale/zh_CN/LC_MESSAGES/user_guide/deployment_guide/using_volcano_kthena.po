# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, vllm-ascend team
# This file is distributed under the same license as the vllm-ascend
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2026.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: vllm-ascend \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-01-08 20:28+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:1
msgid "Using Volcano Kthena"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:3
msgid ""
"This guide shows how to run **prefill–decode (PD) disaggregation** on "
"Huawei Ascend NPUs using **vLLM-Ascend**, with "
"[**Kthena**](https://kthena.volcano.sh/) handling orchestration on "
"Kubernetes. About vLLM support with kthena, please refer to [Deploy vLLM "
"with "
"Kthena](https://docs.vllm.ai/en/latest/deployment/integrations/kthena/)."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:7
msgid "1. What is Prefill–Decode Disaggregation?"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:9
msgid "Large language model inference naturally splits into two phases:"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:11
msgid "**Prefill**"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:12
msgid "Processes input tokens and builds the key–value (KV) cache."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:13
msgid "Batch‑friendly, high throughput, well suited to parallel NPU execution."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:14
msgid "**Decode**"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:15
msgid "Consumes the KV cache to generate output tokens."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:16
msgid "Latency‑sensitive, memory‑intensive, more sequential."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:18
msgid ""
"From the client’s perspective, this still looks like a single Chat / "
"Completions endpoint."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:22
msgid "2. Deploy on Kubernetes with Kthena"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:24
msgid ""
"[Kthena](https://kthena.volcano.sh/) is a Kubernetes-native LLM inference"
" platform that transforms how organizations deploy and manage Large "
"Language Models in production. Built with declarative model lifecycle "
"management and intelligent request routing, it provides high performance "
"and enterprise-grade scalability for LLM inference workloads. In this "
"example, we use three key Custom Resource Definitions (CRDs):"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:26
msgid "`ModelServing` — defines the workloads (prefill and decode roles)."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:27
msgid "`ModelServer` — manages PD groupings and internal routing."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:28
msgid "`ModelRoute` — exposes a stable model endpoint."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:30
msgid ""
"This section uses the `deepseek-ai/DeepSeek-V2-Lite` example, but you can"
" swap in any model supported by vLLM-Ascend."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:32
msgid "2.1 Prerequisites"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:34
msgid "Kubernetes cluster with Ascend NPU nodes:"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:36
msgid ""
"The Resources corresponding to different NPU Drivers may vary slightly. "
"For example:"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:38
#, python-format
msgid ""
"If using [MindCluster](https://gitee.com/ascend/mind-"
"cluster#https://gitee.com/link?target=https%3A%2F%2Fgitcode.com%2FAscend"
"%2Fmind-cluster), please use `huawei.com/Ascend310P` or "
"`huawei.com/Ascend910`."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:40
msgid ""
"If running on CCE (Cloud Container Engine) of Huawei Cloud and the [CCE "
"AI Suite Plugin (Ascend NPU)](https://support.huaweicloud.com/intl/en-us"
"/usermanual-cce/cce_10_0239.html) is installed, please use "
"`huawei.com/ascend-310` or `huawei.com/ascend-1980`."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:42
msgid ""
"Kthena installed. Please follow the [Kthena installation "
"guide](https://kthena.volcano.sh/docs/getting-started/installation)."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:44
msgid "2.2 Deploy Prefill-Decode Disaggregated DeepSeek-V2-Lite on Kubernetes"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:46
msgid ""
"A concrete example is provided in Kthena as https://github.com/volcano-"
"sh/kthena/blob/main/examples/model-serving/prefill-decode-"
"disaggregation.yaml"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:48
msgid "Deploy it with below command:"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:54
#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:315
msgid "or"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:293
msgid "You should see Pods such as:"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:295
msgid "`deepseek-v2-lite-0-prefill-0-0`"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:296
msgid "`deepseek-v2-lite-0-decode-0-0`"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:298
msgid ""
"To enable the llm access, we still need to configure the routing layer "
"with `ModelServer` and `ModelRoute`."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:300
msgid "2.3 ModelServer: PD Group Management"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:302
msgid "The `ModelServer` resource:"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:304
msgid "Selects the `ModelServing` workloads via labels."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:305
msgid "Groups prefill and decode Pods into PD pairs."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:306
msgid "Configures KV connector details and timeouts."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:307
msgid "Exposes an internal gRPC/HTTP interface."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:309
msgid "Create modelServer with below command:"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:345
msgid "2.4 ModelRoute: User-Facing Endpoint"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:347
msgid ""
"The `ModelRoute` resource maps a model name (e.g., `\"deepseek-"
"ai/DeepSeekV2\"`) to the `ModelServer`."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:349
msgid "Example manifest:"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:369
msgid "3. Verification"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:371
msgid "3.1 Check Workloads"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:373
msgid "Confirm that prefill and decode Pods are up:"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:382
msgid "You should see both roles in `Running` and `Ready` state."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:384
msgid "3.2 Test the Chat Endpoint"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:386
msgid ""
"Once routing is configured, you can send a test request to the Kthena-"
"router:"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:406
msgid "A successful JSON response confirms that:"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:408
msgid "The prefill and decode services are both running on Ascend NPUs."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:409
msgid "KV transfer between them is working."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:410
msgid "The Kthena routing layer is correctly fronting the vLLM-Ascend plugin."
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:414
msgid "4. Cleanup"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:416
msgid "To remove the deployment:"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:431
msgid "5. Summary"
msgstr ""

#: ../../source/user_guide/deployment_guide/using_volcano_kthena.md:433
msgid ""
"For more advanced features, please refer to the [Kthena "
"website](https://kthena.volcano.sh/)."
msgstr ""

