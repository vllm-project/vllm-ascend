#: ../../source/tutorials/multi_node_ray.md:1
msgid "Multi-Node-Ray (Qwen/Qwen3-235B-A22B)"
msgstr "多节点 Ray（Qwen / Qwen3-235B-A22B）"

#: ../../source/tutorials/multi_node_ray.md:3
msgid ""
"Multi-node inference is suitable for scenarios where the model cannot be "
"deployed on a single machine. In such cases, the model can be distributed"
" using tensor parallelism or pipeline parallelism. The specific "
"parallelism strategies will be covered in the following sections. To "
"successfully deploy multi-node inference, the following three steps need "
"to be completed:"
msgstr ""
"多节点推理适用于模型无法部署在单台机器上的场景。在这种情况下，可以通过张量并行或流水线并行的方式对模型进行分布式部署。具体的并行策略将在后续章节中介绍。要成功部署多节点推理，需要完成以下三个步骤："

#: ../../source/tutorials/multi_node_ray.md:5
msgid "**Verify Multi-Node Communication Environment**"
msgstr "**验证多节点通信环境**"

#: ../../source/tutorials/multi_node_ray.md:6
msgid "**Set Up and Start the Ray Cluster**"
msgstr "**搭建并启动 Ray 集群**"

#: ../../source/tutorials/multi_node_ray.md:7
msgid "**Start the Online Inference Service on Multi-node**"
msgstr "**在多节点场景下启动在线推理服务**"

#: ../../source/tutorials/multi_node_ray.md:9
msgid "Verify Multi-Node Communication Environment"
msgstr "验证多节点通信环境"

#: ../../source/tutorials/multi_node_ray.md:11
msgid "Physical Layer Requirements:"
msgstr "物理层要求："

#: ../../source/tutorials/multi_node_ray.md:13
msgid ""
"The physical machines must be located on the same LAN, with network "
"connectivity."
msgstr ""
"物理机器必须位于同一个局域网内，并且网络互通。"

#: ../../source/tutorials/multi_node_ray.md:14
msgid ""
"All NPUs are connected with optical modules, and the connection status "
"must be normal."
msgstr ""
"所有 NPU 必须通过光模块连接，且连接状态正常。"

#: ../../source/tutorials/multi_node_ray.md:16
msgid "Verification Process:"
msgstr "验证流程："

#: ../../source/tutorials/multi_node_ray.md:18
msgid ""
"Execute the following commands on each node in sequence. The results must"
" all be `success` and the status must be `UP`:"
msgstr ""
"在每个节点上依次执行以下命令，执行结果必须全部为 `success`，且状态必须为 `UP`："

#: ../../source/tutorials/multi_node_ray.md:35
msgid "NPU Interconnect Verification:"
msgstr "NPU 互联验证："

#: ../../source/tutorials/multi_node_ray.md:36
msgid "1. Get NPU IP Addresses"
msgstr "1. 获取 NPU IP 地址"

#: ../../source/tutorials/multi_node_ray.md:42
msgid "2. Cross-Node PING Test"
msgstr "2. 跨节点 PING 测试"

#: ../../source/tutorials/multi_node_ray.md:49
msgid "Set Up and Start the Ray Cluster"
msgstr "搭建并启动 Ray 集群"

#: ../../source/tutorials/multi_node_ray.md:50
msgid "Setting Up the Basic Container"
msgstr "基础容器环境搭建"

#: ../../source/tutorials/multi_node_ray.md:51
msgid ""
"To ensure a consistent execution environment across all nodes, including "
"the model path and Python environment, it is advised to use Docker "
"images."
msgstr ""
"为了确保所有节点上的执行环境一致（包括模型路径和 Python 环境），建议使用 Docker 镜像。"

#: ../../source/tutorials/multi_node_ray.md:53
msgid ""
"For setting up a multi-node inference cluster with Ray, **containerized "
"deployment** is the preferred approach. Containers should be started on "
"both the primary and secondary nodes, with the `--net=host` option to "
"enable proper network connectivity."
msgstr ""
"在使用 Ray 搭建多节点推理集群时，**容器化部署**是首选方案。需要在主节点和从节点上均启动容器，并使用 `--net=host` 选项以保证网络连通性。"

#: ../../source/tutorials/multi_node_ray.md:55
msgid ""
"Below is the example container setup command, which should be executed on"
" **all nodes** :"
msgstr ""
"下面是示例容器启动命令，需要在 **所有节点** 上执行："

#: ../../source/tutorials/multi_node_ray.md:89
msgid "Start Ray Cluster"
msgstr "启动 Ray 集群"

#: ../../source/tutorials/multi_node_ray.md:90
msgid ""
"After setting up the containers and installing vllm-ascend on each node, "
"follow the steps below to start the Ray cluster and execute inference "
"tasks."
msgstr ""
"在每个节点完成容器搭建并安装 vllm-ascend 后，按照以下步骤启动 Ray 集群并执行推理任务。"

#: ../../source/tutorials/multi_node_ray.md:92
msgid ""
"Choose one machine as the primary node and the others as secondary nodes."
" Before proceeding, use `ip addr` to check your `nic_name` (network "
"interface name)."
msgstr ""
"选择一台机器作为主节点，其余机器作为从节点。在继续之前，请使用 `ip addr` 查看你的 `nic_name`（网络接口名称）。"

#: ../../source/tutorials/multi_node_ray.md:94
msgid ""
"Set the `ASCEND_RT_VISIBLE_DEVICES` environment variable to specify the "
"NPU devices to use. For Ray versions above 2.1, also set the "
"`RAY_EXPERIMENTAL_NOSET_ASCEND_RT_VISIBLE_DEVICES` variable to avoid "
"device recognition issues."
msgstr ""
"设置 `ASCEND_RT_VISIBLE_DEVICES` 环境变量以指定要使用的 NPU 设备。对于 2.1 以上版本的 Ray，还需要设置 `RAY_EXPERIMENTAL_NOSET_ASCEND_RT_VISIBLE_DEVICES` 变量，以避免设备识别问题。"

#: ../../source/tutorials/multi_node_ray.md:96
msgid "Below are the commands for the primary and secondary nodes:"
msgstr "以下是主节点和从节点的命令："

#: ../../source/tutorials/multi_node_ray.md:98
msgid "**Primary node**:"
msgstr "**主节点**："

#: ../../source/tutorials/multi_node_ray.md:101
#: ../../source/tutorials/multi_node_ray.md:118
msgid ""
"When starting a Ray cluster for multi-node inference, the environment "
"variables on each node must be set **before** starting the Ray cluster "
"for them to take effect. Updating the environment variables requires "
"restarting the Ray cluster."
msgstr ""
"在启动用于多节点推理的 Ray 集群时，必须在启动 Ray 集群 **之前** 设置好各节点上的环境变量，这样配置才能生效。若更新环境变量，需要重启 Ray 集群。"

#: ../../source/tutorials/multi_node_ray.md:115
msgid "**Secondary node**:"
msgstr "**从节点**："

#: ../../source/tutorials/multi_node_ray.md:131
msgid ""
"Once the cluster is started on multiple nodes, execute `ray status` and "
"`ray list nodes` to verify the Ray cluster's status. You should see the "
"correct number of nodes and NPUs listed."
msgstr ""
"当集群在多个节点上启动完成后，执行 `ray status` 和 `ray list nodes` 来验证 Ray 集群的状态。你应该能看到正确数量的节点和 NPU 列表。"

#: ../../source/tutorials/multi_node_ray.md:133
msgid "Start the Online Inference Service on Multi-node scenario"
msgstr "在多节点场景下启动在线推理服务"

#: ../../source/tutorials/multi_node_ray.md:134
msgid ""
"In the container, you can use vLLM as if all NPUs were on a single node. "
"vLLM will utilize NPU resources across all nodes in the Ray cluster."
msgstr ""
"在容器中，你可以像在单节点上一样使用 vLLM。vLLM 会利用 Ray 集群中所有节点的 NPU 资源。"

#: ../../source/tutorials/multi_node_ray.md:136
msgid "**You only need to run the vllm command on one node.**"
msgstr "**你只需要在其中一个节点上运行 vllm 命令。**"

#: ../../source/tutorials/multi_node_ray.md:138
msgid ""
"To set up parallelism, the common practice is to set the `tensor-"
"parallel-size` to the number of NPUs per node, and the `pipeline-"
"parallel-size` to the number of nodes."
msgstr ""
"在配置并行策略时，通常将 `tensor-parallel-size` 设置为每个节点上的 NPU 数量，将 `pipeline-parallel-size` 设置为节点数量。"

#: ../../source/tutorials/multi_node_ray.md:140
msgid ""
"For example, with 16 NPUs across 2 nodes (8 NPUs per node), set the "
"tensor parallel size to 8 and the pipeline parallel size to 2:"
msgstr ""
"例如，在 2 个节点上共使用 16 个 NPU（每个节点 8 个 NPU）的情况下，将张量并行大小设置为 8，将流水线并行大小设置为 2："

#: ../../source/tutorials/multi_node_ray.md:156
msgid ""
"Alternatively, if you want to use only tensor parallelism, set the tensor"
" parallel size to the total number of NPUs in the cluster. For example, "
"with 16 NPUs across 2 nodes, set the tensor parallel size to 16:"
msgstr ""
"另外，如果只使用张量并行，则可以将张量并行大小设置为集群中 NPU 的总数量。例如，在 2 个节点上共 16 个 NPU 的情况下，将张量并行大小设置为 16："

#: ../../source/tutorials/multi_node_ray.md:171
msgid "Once your server is started, you can query the model with input prompts:"
msgstr "当服务启动后，你可以通过输入提示词来查询模型："
